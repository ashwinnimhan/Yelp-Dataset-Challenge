package task2;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Set;
import org.apache.lucene.document.Document;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;
import task1.EvaluateReview;
import task1.Task1IR;
import task1.TrainReview;

public class CitiesTrainModel {
	static String curDir;
	final static String nlpDir = "stanford-corenlp-full-2015-04-20";   // directory in which stanford Core NLP is installed
	final static String nlpOutputFile = "input.txt.xml";               // output file generated by Core NLP 
	final static String nlpInputFile = "input.txt";                    // input file to Core NLP
	final static String nlpConfigFile = "config.properties";           // configuration file
	final static String restaurantCategoryFile = "categories.txt";     // file which contains only restaurant categories 
	final static int businessReviewCountLimit = 10;
	static List<String> listCities;
	static HashMap<String, String> hashCat;
	static HashMap<String, Float> hashBusiness;
	static HashMap<String, String> hashBusinessReview;
	static HashMap<String, Set<String>> hashModelFeature;
	static HashMap<String, HashMap<String, Set<String>>> hashBusFeatureOpinion;
	static HashMap<String, Set<String>> hashFeatureBusList;
	static HashMap<String, Integer> hashBusinessReviewCount;
	
	public static String getCurDir(){
		return curDir;
	}
	
	public static String getNlpDir(){
		return nlpDir;
	}

	public static String getNlpOutputFile(){
		return nlpOutputFile;
	}
	
	public static String getNlpInputFile(){
		return nlpInputFile;
	}
	
	public static String getNlpConfigFile(){
		return nlpConfigFile;
	}
	
	static void init(){
		curDir = System.getProperty("user.dir");
		hashBusinessReview = new HashMap<String, String>();
		hashCat = new HashMap<String, String>();
		hashBusiness = new HashMap<String, Float>();
		hashModelFeature = new HashMap<String, Set<String>>();
		hashBusFeatureOpinion = new HashMap<String, HashMap<String, Set<String>>>();
		hashFeatureBusList = new HashMap<String, Set<String>>();
		hashBusinessReviewCount = new HashMap<String, Integer>();		
	}
	
	static void buildSetup() throws Exception{
		init();
		TrainReview.initSetUp();
		EvaluateReview.initSetUp();
		TestData.buildSetup();
		XMLParser.init();
		buildHashCat();	
	}
	
	static void display(){
		Set<String> set = hashBusFeatureOpinion.keySet();
		Iterator<String> it = set.iterator();
		
		
		while(it.hasNext()){
			String business_id = it.next();
			System.out.println("Business Id: "+business_id);
			HashMap<String, Set<String>> hash = hashBusFeatureOpinion.get(business_id);
			
			Set<String> setHash = hash.keySet();
			Iterator<String> itHash = setHash.iterator();
			
			while(itHash.hasNext()){
				String feature = itHash.next();
				System.out.println("Feature: "+feature);
				
				Set<String> setOp = hash.get(feature);
				for(String s : setOp){
					System.out.print(s+", ");
				}
				System.out.println("\n---------------------------");
				
			}
			
		}
		
	}
	
	
	//Below method reads from categories.txt and puts the categories in a HashMap
	static void buildHashCat() throws Exception{
		FileReader fr = new FileReader(curDir+"\\corpus1\\"+restaurantCategoryFile);
		BufferedReader br = new BufferedReader(fr);
		String s = "";
		
		while((s=br.readLine())!=null)
			hashCat.put(s, s);
		
		br.close();
	}	
	
	//Below method reads from the Lucene index and puts the reviews in the HashMap hashBusinessReview
	static void buildBusinessReview() throws Exception{
		String review = "";
		int startDoc = 0;
		int endDoc = 500;
		int reviewCount = 0;
		
		while(endDoc <= 800000){
			for(int docId=startDoc;docId<endDoc;docId++){
				Document doc = TrainReview.getIndexSearcher().doc(docId);
				String business_id = doc.get("BUSID");
				
				if(hashBusiness.containsKey(business_id)){
					review = doc.get("REVIEW"); 
					
					if(!hashBusinessReview.containsKey(business_id)){
						hashBusinessReview.put(business_id, review);
						hashBusinessReviewCount.put(business_id, 1);
					 }
					else{
						reviewCount = hashBusinessReviewCount.get(business_id);
					    if(reviewCount <= businessReviewCountLimit)
					    	hashBusinessReview.put(business_id, hashBusinessReview.get(business_id)+"\n "+review);
					}
				}
			}
			
			startDoc += 500;
			endDoc += 500;
		}
			
	}
	
	// **Core Method**
	// Below method iterates through the reviews in hashBusinessReview and passes the reviews to CoreNLP one at a time...
	// The output(input.txt.xml) generated by CoreNLP is parsed to identify the nouns(features) and adjectives(opinions) 
	static void buildFeatureList() throws Exception{
		Set<String> set = hashBusinessReview.keySet();
		Iterator<String> it = set.iterator();
		
		while(it.hasNext()){
			String business_id = it.next();
			writeNLPInputFile(null, hashBusinessReview.get(business_id));
			
			SentimentAnalyzer.analyzeSentence(false);  // calls the CoreNLP parser to generate the output file(input.txt.xml)
			File file = new File("C:\\Users\\Shrijit\\Documents\\IU\\Fall2015\\Advanced NLP\\"+nlpDir+"\\"+nlpOutputFile);
			
			XMLParser.parseXML(file, false); // parses the output xml file and builds the features and sentiments
			RecommendItems.identifySentence(XMLParser.words, XMLParser.hashOpinionList, business_id); // determines the recommended and non-recommended features
			XMLParser.hashOpinionList.clear();
		}
	}
	
	//Below method reads the training file and puts the business id as the key and its rating as the value in the HashMap
	public static void buildHashBusiness(Object obj) throws Exception{
		JSONObject jObject = (JSONObject)obj;
		String business_id = jObject.get("business_id") + "";
		float rating = Float.parseFloat(jObject.get("stars") + "");
		
		String review = jObject.get("text") + "";	
		hashBusiness.put(business_id, rating);

		if(!hashBusinessReview.containsKey(business_id))
			hashBusinessReview.put(business_id, review);
		else	
			hashBusinessReview.put(business_id, hashBusinessReview.get(business_id)+" "+review);
	}
	
	// Below method checks if the record in the data file corresponds to a restaurant 
	public static boolean isRestaurant(Object obj){
		JSONObject jObject = (JSONObject)obj;
		JSONArray catObj = (JSONArray)jObject.get("categories");
		
		for(int i=0;i<catObj.size();i++){
			if(hashCat.containsKey(catObj.get(i))){
				return true;
			}
		}
		
		return false;
	}
	
	// Below method writes the review to file which will be input to the CoreNLP parser
	public static void writeNLPInputFile(HashMap<String, String> hash, String review) throws IOException{
		
		FileWriter fw = new FileWriter("C:\\Users\\Shrijit\\Documents\\IU\\Fall2015\\Advanced NLP\\"+nlpDir+"\\"+nlpInputFile);
		
		if(hash!=null){
		   Set<String> set = hash.keySet();
		   Iterator<String> it = set.iterator();
			
		   while(it.hasNext()){
			  String key = it.next();
			  fw.write(hash.get(key)+"\n");
		   }
		 }
		else{
			fw.write(review+"\n");
		}
		
		fw.close();
	}
	
	
	// Below method extracts records from the json file and writes to a file
	public static void extractRecords(String fileName, int option, FileWriter fw) throws Exception{
		File file = new File(curDir+"\\corpus1\\"+fileName);
		Task1IR.parseJsonFile(file, option, fw);
	}
	
	
	// Below method puts the features and the sentiments in a HashMap
	public static void buildHashModelFeature(){
		Set<String> set = XMLParser.hashFeatureFreq.keySet();
		Iterator<String> it = set.iterator();
		
		while(it.hasNext()){
			String key = it.next();
			int freq = XMLParser.hashFeatureFreq.get(key);
			
			if(XMLParser.hashOpinionList.containsKey(key) && freq>=5){				
				Set<String> temp = XMLParser.hashOpinionList.get(key);
			    hashModelFeature.put(key, temp);
			}
				
		 }
	}

}
